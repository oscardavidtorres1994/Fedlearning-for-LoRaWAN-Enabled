{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfTrain=pd.read_csv(\"./Data Sample Centralized/Train.csv\")\n",
    "dfTest=pd.read_csv(\"./Data Sample Centralized/Test.csv\")\n",
    "dfValidation=pd.read_csv(\"./Data Sample Centralized/Validation.csv\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns to be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['EngSpeed', 'EngOilPress', 'EngCoolantTemp', 'EngFuelRate', 'BatteryPotential_PowerInput1']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model and determine threshold values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, precision_score, recall_score, roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the number of input features (columns in the dataset)\n",
    "input_dim = len(columns)  # Number of features\n",
    "encoding_dim = 128  # Number of neurons in the encoding layer\n",
    "\n",
    "# Columns that require modifications based on specific conditions\n",
    "\n",
    "# Define the Autoencoder model\n",
    "autoencoder = keras.Sequential([\n",
    "    layers.Input(shape=(input_dim,)),  # Input layer with input dimension\n",
    "    layers.Dense(encoding_dim, activation='tanh'),  # First hidden layer\n",
    "    layers.Dense(2, activation='tanh'),  # Bottleneck layer (compressed representation)\n",
    "    layers.Dense(encoding_dim, activation='tanh'),  # Expansion layer\n",
    "    layers.Dense(input_dim, activation='tanh')  # Output layer (reconstructing input)\n",
    "    # layers.Dense(input_dim, activation='sigmoid')  # Alternative activation\n",
    "])\n",
    "\n",
    "# Compile the model using Adam optimizer and mean squared error loss\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the autoencoder on the training dataset\n",
    "autoencoder.fit(\n",
    "    dfTrain[columns], dfTrain[columns], \n",
    "    epochs=100, batch_size=64, shuffle=True, verbose=False,\n",
    "    validation_data=(dfValidation[columns], dfValidation[columns])\n",
    ")\n",
    "\n",
    "# Extract validation data for evaluation\n",
    "x_val = dfValidation[columns]\n",
    "\n",
    "# Generate predictions using the trained autoencoder\n",
    "predictions = autoencoder.predict(x_val)\n",
    "\n",
    "# Compute the Mean Squared Error (MSE) for each feature\n",
    "# mse = pd.DataFrame(np.power(x_val - predictions, 2), columns=columns)\n",
    "\n",
    "\n",
    "mse = np.mean(np.power(x_val - predictions, 2), axis=1)\n",
    "\n",
    "# Dictionary to store the best threshold for each feature\n",
    "best_thresholds = {}\n",
    "\n",
    "# Iterate over each feature to find the best threshold using F1-score\n",
    "\n",
    "# mse_column = mse  # Get MSE values for the column\n",
    "best_f1 = 0  # Initialize best F1-score\n",
    "best_threshold = 0  # Initialize best threshold value\n",
    "\n",
    "# Try different percentile-based thresholds (from 50% to 100%)\n",
    "for threshold_value in range(50, 101):\n",
    "    threshold = np.percentile(mse, threshold_value)  # Compute percentile threshold\n",
    "    anomaly_labels = (mse > threshold)  # Identify anomalies\n",
    "    y_pred_bool = ~anomaly_labels  # Convert to boolean normal/abnormal labels\n",
    "    \n",
    "    # Apply additional condition for specific columns\n",
    "\n",
    "    \n",
    "    y_test = dfValidation[\"normal_label\"]  # Get actual labels\n",
    "    \n",
    "    # Compute F1-score\n",
    "    f1 = f1_score(y_test, y_pred_bool)\n",
    "    \n",
    "    # Update the best threshold if F1-score improves\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "        best_threshold_value = threshold_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 0s/step\n",
      "  Accuracy Precision  Recall F1 Score ROC AUC  PR AUC  TP  TN  FP  FN     TPR  \\\n",
      "0   85.86%    95.40%  89.25%   92.22%  61.29%  95.24%  83   2   4  10  89.25%   \n",
      "\n",
      "      FNR     TNR     FPR  \n",
      "0  10.75%  33.33%  66.67%  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (f1_score, confusion_matrix, accuracy_score, \n",
    "                             precision_score, recall_score, roc_auc_score, average_precision_score)\n",
    "\n",
    "\n",
    "\n",
    "# Extract test data based on selected columns\n",
    "x_test = dfTest[columns]\n",
    "\n",
    "# Predict results using the autoencoder\n",
    "results = autoencoder.predict(x_test)\n",
    "\n",
    "# Compute Mean Squared Error (MSE) for each column\n",
    "mse = np.mean(np.power(x_test - results, 2), axis=1)\n",
    "\n",
    "\n",
    "# Iterate over columns to determine anomalies\n",
    "\n",
    "anomaly_labels = (mse > best_threshold)\n",
    "y_pred_bool = ~anomaly_labels\n",
    "\n",
    "\n",
    "dfTest[\"normal_label_pred\"] = y_pred_bool\n",
    "\n",
    "\n",
    "\n",
    "# Extract actual and predicted labels for evaluation\n",
    "y_test_global = dfTest[\"normal_label\"]\n",
    "y_pred_global = dfTest['normal_label_pred']\n",
    "\n",
    "# Compute evaluation metrics\n",
    "confusion = confusion_matrix(y_test_global, y_pred_global)\n",
    "accuracy = accuracy_score(y_test_global, y_pred_global)\n",
    "precision = precision_score(y_test_global, y_pred_global)\n",
    "recall = recall_score(y_test_global, y_pred_global)\n",
    "f1 = f1_score(y_test_global, y_pred_global)\n",
    "roc_auc = roc_auc_score(y_test_global, y_pred_global)\n",
    "pr_auc = average_precision_score(y_test_global, y_pred_global)\n",
    "\n",
    "# Extract values from confusion matrix\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "\n",
    "# Compute additional evaluation metrics\n",
    "TPR = TP / (TP + FN)  # Sensitivity\n",
    "FNR = FN / (FN + TP)  # False Negative Rate\n",
    "TNR = TN / (TN + FP)  # Specificity\n",
    "FPR = FP / (FP + TN)  # False Positive Rate\n",
    "\n",
    "# Create DataFrame to store results without additional statistics\n",
    "df_resultados_globales = pd.DataFrame([{\n",
    "    \"Accuracy\": accuracy,\n",
    "    \"Precision\": precision,\n",
    "    \"Recall\": recall,\n",
    "    \"F1 Score\": f1,\n",
    "    \"ROC AUC\": roc_auc,\n",
    "    \"PR AUC\": pr_auc,\n",
    "    \"TP\": TP,\n",
    "    \"TN\": TN,\n",
    "    \"FP\": FP,\n",
    "    \"FN\": FN,\n",
    "    \"TPR\": TPR,\n",
    "    \"FNR\": FNR,\n",
    "    \"TNR\": TNR,\n",
    "    \"FPR\": FPR\n",
    "}])\n",
    "\n",
    "# Format percentage-based metrics properly\n",
    "columns_to_exclude = [\"TP\", \"TN\", \"FP\", \"FN\"]\n",
    "for col in df_resultados_globales.columns:\n",
    "    if col not in columns_to_exclude:\n",
    "        df_resultados_globales[col] = df_resultados_globales[col].apply(lambda x: f\"{x*100:.2f}%\")\n",
    "\n",
    "# Print and save the results\n",
    "print(df_resultados_globales)\n",
    "df_resultados_globales.to_csv(\"results.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
